{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1,
      "grad_norm": 52925.62509786729,
      "learning_rate": 2.857142857142857e-05,
      "loss": 1.1096,
      "step": 10
    },
    {
      "epoch": 0.2,
      "grad_norm": 44917.04852280479,
      "learning_rate": 5.714285714285714e-05,
      "loss": 1.0997,
      "step": 20
    },
    {
      "epoch": 0.3,
      "grad_norm": 33724.18953807489,
      "learning_rate": 8.571428571428571e-05,
      "loss": 0.8436,
      "step": 30
    },
    {
      "epoch": 0.4,
      "grad_norm": 23479.565242993747,
      "learning_rate": 0.00011428571428571428,
      "loss": 0.7293,
      "step": 40
    },
    {
      "epoch": 0.5,
      "grad_norm": 33442.79031420674,
      "learning_rate": 0.00014285714285714287,
      "loss": 0.6987,
      "step": 50
    },
    {
      "epoch": 0.6,
      "grad_norm": 42218.447531855076,
      "learning_rate": 0.00017142857142857143,
      "loss": 0.5338,
      "step": 60
    },
    {
      "epoch": 0.7,
      "grad_norm": 31504.005078719754,
      "learning_rate": 0.0002,
      "loss": 0.5907,
      "step": 70
    },
    {
      "epoch": 0.8,
      "grad_norm": 29326.962338435256,
      "learning_rate": 0.00019987569212189224,
      "loss": 0.5857,
      "step": 80
    },
    {
      "epoch": 0.9,
      "grad_norm": 26565.281402612698,
      "learning_rate": 0.00019950307753654017,
      "loss": 0.5815,
      "step": 90
    },
    {
      "epoch": 1.0,
      "grad_norm": 34297.05899927864,
      "learning_rate": 0.00019888308262251285,
      "loss": 0.5331,
      "step": 100
    },
    {
      "epoch": 1.1,
      "grad_norm": 44180.656038587746,
      "learning_rate": 0.00019801724878485438,
      "loss": 0.5428,
      "step": 110
    },
    {
      "epoch": 1.2,
      "grad_norm": 36308.24126834017,
      "learning_rate": 0.0001969077286229078,
      "loss": 0.4796,
      "step": 120
    },
    {
      "epoch": 1.3,
      "grad_norm": 35090.936493630375,
      "learning_rate": 0.0001955572805786141,
      "loss": 0.456,
      "step": 130
    },
    {
      "epoch": 1.4,
      "grad_norm": 38544.54628089427,
      "learning_rate": 0.00019396926207859084,
      "loss": 0.398,
      "step": 140
    },
    {
      "epoch": 1.5,
      "grad_norm": 35538.62214549124,
      "learning_rate": 0.00019214762118704076,
      "loss": 0.4366,
      "step": 150
    },
    {
      "epoch": 1.6,
      "grad_norm": 43426.81346817885,
      "learning_rate": 0.0001900968867902419,
      "loss": 0.4471,
      "step": 160
    },
    {
      "epoch": 1.7,
      "grad_norm": 28794.700623552246,
      "learning_rate": 0.00018782215733702286,
      "loss": 0.4163,
      "step": 170
    },
    {
      "epoch": 1.8,
      "grad_norm": 33954.05837304283,
      "learning_rate": 0.00018532908816321558,
      "loss": 0.4604,
      "step": 180
    },
    {
      "epoch": 1.9,
      "grad_norm": 43507.751217455494,
      "learning_rate": 0.0001826238774315995,
      "loss": 0.4538,
      "step": 190
    },
    {
      "epoch": 2.0,
      "grad_norm": 41690.357254405964,
      "learning_rate": 0.00017971325072229226,
      "loss": 0.4288,
      "step": 200
    },
    {
      "epoch": 2.1,
      "grad_norm": 35554.54356337598,
      "learning_rate": 0.0001766044443118978,
      "loss": 0.3012,
      "step": 210
    },
    {
      "epoch": 2.2,
      "grad_norm": 48946.379804843586,
      "learning_rate": 0.00017330518718298264,
      "loss": 0.2947,
      "step": 220
    },
    {
      "epoch": 2.3,
      "grad_norm": 44900.36614550042,
      "learning_rate": 0.00016982368180860728,
      "loss": 0.258,
      "step": 230
    },
    {
      "epoch": 2.4,
      "grad_norm": 45661.77990398535,
      "learning_rate": 0.00016616858375968595,
      "loss": 0.3116,
      "step": 240
    },
    {
      "epoch": 2.5,
      "grad_norm": 38362.46999347148,
      "learning_rate": 0.00016234898018587337,
      "loss": 0.3038,
      "step": 250
    },
    {
      "epoch": 2.6,
      "grad_norm": 50735.91674543784,
      "learning_rate": 0.000158374367223479,
      "loss": 0.2864,
      "step": 260
    },
    {
      "epoch": 2.7,
      "grad_norm": 45028.21870782809,
      "learning_rate": 0.00015425462638657595,
      "loss": 0.2755,
      "step": 270
    },
    {
      "epoch": 2.8,
      "grad_norm": 47264.26269392129,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.259,
      "step": 280
    },
    {
      "epoch": 2.9,
      "grad_norm": 48831.59632860675,
      "learning_rate": 0.0001456210657353163,
      "loss": 0.2649,
      "step": 290
    },
    {
      "epoch": 3.0,
      "grad_norm": 56216.636968072,
      "learning_rate": 0.00014112871031306119,
      "loss": 0.3098,
      "step": 300
    },
    {
      "epoch": 3.1,
      "grad_norm": 47561.692148198425,
      "learning_rate": 0.00013653410243663952,
      "loss": 0.1556,
      "step": 310
    },
    {
      "epoch": 3.2,
      "grad_norm": 64162.77699725909,
      "learning_rate": 0.00013184866502516845,
      "loss": 0.1457,
      "step": 320
    },
    {
      "epoch": 3.3,
      "grad_norm": 52787.0820561243,
      "learning_rate": 0.00012708404681430053,
      "loss": 0.1504,
      "step": 330
    },
    {
      "epoch": 3.4,
      "grad_norm": 43627.37929328325,
      "learning_rate": 0.00012225209339563145,
      "loss": 0.1374,
      "step": 340
    },
    {
      "epoch": 3.5,
      "grad_norm": 52395.588211222515,
      "learning_rate": 0.00011736481776669306,
      "loss": 0.1389,
      "step": 350
    },
    {
      "epoch": 3.6,
      "grad_norm": 67964.76075143648,
      "learning_rate": 0.00011243437046474853,
      "loss": 0.1314,
      "step": 360
    },
    {
      "epoch": 3.7,
      "grad_norm": 50647.5596253166,
      "learning_rate": 0.00010747300935864243,
      "loss": 0.1764,
      "step": 370
    },
    {
      "epoch": 3.8,
      "grad_norm": 49077.89726546972,
      "learning_rate": 0.0001024930691738073,
      "loss": 0.1493,
      "step": 380
    },
    {
      "epoch": 3.9,
      "grad_norm": 58627.978030970844,
      "learning_rate": 9.750693082619273e-05,
      "loss": 0.1532,
      "step": 390
    },
    {
      "epoch": 4.0,
      "grad_norm": 51819.423076680425,
      "learning_rate": 9.252699064135758e-05,
      "loss": 0.1272,
      "step": 400
    }
  ],
  "logging_steps": 10,
  "max_steps": 700,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 7,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6640602623901696e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
